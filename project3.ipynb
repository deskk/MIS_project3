{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gdC70xxFyc4"
      },
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9_7SnpMGKDJ"
      },
      "source": [
        "# 1. Fashion-MNIST image classification using sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB136H0PGKq1",
        "outputId": "b15d500a-05c3-4018-847e-5588bee4546f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(len(X_train), -1)\n",
        "X_test  = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GAsN-dmHjRM"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, f1_score\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I81cl9VyTOYe"
      },
      "outputs": [],
      "source": [
        "class_names = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTfTgRWAk5AZ"
      },
      "source": [
        "## baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SbV9018CbD-"
      },
      "source": [
        "modify hidden_layer_sizes, activation_functions, solver, learning_rate, learning_rate_init, alpha, early_stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W28ZtNX2NQY0",
        "outputId": "1ffa998c-b615-47b5-8157-8ee7ac677c00"
      },
      "outputs": [],
      "source": [
        "# 1 hidden layer with 100 neurons\n",
        "# adam optimizer, early_stopping is true\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=100,\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.0001,\n",
        "    learning_rate='constant',\n",
        "    learning_rate_init=0.001,\n",
        "    # verbose=True,\n",
        "    early_stopping=True,\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "mlp.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "training_time = end - start\n",
        "print(f\"Training time: {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBzvCISxGEyj"
      },
      "outputs": [],
      "source": [
        "y_pred = mlp.predict(X_test)\n",
        "y_proba = mlp.predict_proba(X_test) # auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7qWpJtDEDbJ",
        "outputId": "9ac3e8d0-b49f-49e0-c273-bd445d4aef86"
      },
      "outputs": [],
      "source": [
        "# training and convergence\n",
        "\n",
        "print(f\"Model converged in {mlp.n_iter_} epochs (max_iter was {mlp.max_iter}).\")\n",
        "print(f\"Final training loss: {mlp.loss_:.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsvVKkd6Svqg",
        "outputId": "8dea2267-9747-430b-83f8-bf36f590abd7"
      },
      "outputs": [],
      "source": [
        "# classification result\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=class_names)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yhNEAtbTjBc",
        "outputId": "a091b2df-61a7-4e50-b2ca-0ea2d65222d0"
      },
      "outputs": [],
      "source": [
        "# roc score (one vs rest for multi-class classification)\n",
        "\n",
        "auc_macro = roc_auc_score(y_test, y_proba, multi_class='ovr', average='macro')\n",
        "\n",
        "auc_weighted = roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted')\n",
        "\n",
        "print(f\"AUC (macro): {auc_macro:.4f}\")\n",
        "print(f\"AUC (weighted): {auc_weighted:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "SUZeqUpLUDk6",
        "outputId": "033fddf7-9e11-4166-b52c-b797468359a6"
      },
      "outputs": [],
      "source": [
        "# training loss curve\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(mlp.loss_curve_)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Training Loss Curve', fontsize=16)\n",
        "# plt.grid(True)\n",
        "plt.annotate(\n",
        "    f'Convergence at Epoch {mlp.n_iter_}',\n",
        "    xy=(mlp.n_iter_, mlp.loss_curve_[-1]),\n",
        "    xytext=(mlp.n_iter_ - 4, mlp.loss_curve_[-1] + 0.1),\n",
        "    # arrowprops=dict(facecolor='black', shrink=0.05),\n",
        "    horizontalalignment='center',\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "4qKDwRktXNNO",
        "outputId": "d119ebf9-9fb9-4f75-8be8-675160e0063b"
      },
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "disp.plot(cmap=plt.cm.GnBu, ax=ax, xticks_rotation='vertical')\n",
        "plt.title(\"Confusion Matrix\", fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l89q8STUk8dI"
      },
      "source": [
        "## ablation study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OujFt3KvcwJ",
        "outputId": "9dc30242-2078-4678-91da-a2a4062d5a6f"
      },
      "outputs": [],
      "source": [
        "ablation_configs = [\n",
        "    {'name': 'Study 1', 'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver':'adam', 'learning_rate_init':0.001, 'alpha': 0.0001, 'early_stopping':False},\n",
        "    {'name': 'Study 2', 'hidden_layer_sizes': (50,50,50), 'activation': 'relu', 'solver':'adam', 'learning_rate_init':0.001, 'alpha': 0.0001, 'early_stopping':False},\n",
        "    {'name': 'Study 3', 'hidden_layer_sizes': (300,100), 'activation': 'relu', 'solver':'adam', 'learning_rate_init':0.001, 'alpha': 0.0001, 'early_stopping':False},\n",
        "    {'name': 'Study 4', 'hidden_layer_sizes': (100,), 'activation': 'logistic', 'solver':'adam', 'learning_rate_init':0.001, 'alpha': 0.0001, 'early_stopping':False},\n",
        "    {'name': 'Study 5', 'hidden_layer_sizes': (100,), 'activation': 'tanh', 'solver':'adam', 'learning_rate_init':0.001, 'alpha': 0.0001, 'early_stopping':False},\n",
        "    {'name': 'Study 6', 'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver':'sgd', 'learning_rate_init':0.001, 'alpha': 0.0001, 'early_stopping':False},\n",
        "    {'name': 'Study 7', 'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver':'adam', 'learning_rate_init':0.01, 'alpha': 0.0001, 'early_stopping':False},\n",
        "    {'name': 'Study 8', 'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver':'sgd', 'learning_rate_init':0.0001, 'alpha': 0.0001, 'early_stopping':False},\n",
        "    {'name': 'Study 9', 'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver':'adam', 'learning_rate_init':0.001, 'alpha': 0.1, 'early_stopping':False},\n",
        "    {'name': 'Study 10', 'hidden_layer_sizes': (100,), 'activation': 'relu', 'solver':'adam', 'learning_rate_init':0.001, 'alpha': 0.0001, 'early_stopping':True},\n",
        "    {'name': 'Study 11', 'hidden_layer_sizes': (50,50,50), 'activation': 'relu', 'solver':'adam', 'learning_rate_init':0.001, 'alpha': 0.1, 'early_stopping':False},\n",
        "    {'name': 'Study 12', 'hidden_layer_sizes': (300,100), 'activation': 'tanh', 'solver':'sgd', 'learning_rate_init':0.01, 'alpha': 0.0001, 'early_stopping':True},\n",
        "]\n",
        "\n",
        "results = {}\n",
        "all_loss_curves = {}\n",
        "all_cms = {}\n",
        "summary_metrics = []\n",
        "\n",
        "for config in ablation_configs:\n",
        "  ablation_name = config.pop('name')\n",
        "  print(f\" training {ablation_name} \")\n",
        "\n",
        "  mlp = MLPClassifier(**config)\n",
        "\n",
        "  start = time.time()\n",
        "  mlp.fit(X_train, y_train)\n",
        "  end = time.time()\n",
        "\n",
        "  y_pred = mlp.predict(X_test)\n",
        "  y_proba = mlp.predict_proba(X_test) # auc\n",
        "  # acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "  all_loss_curves[ablation_name] = mlp.loss_curve_\n",
        "  all_cms[ablation_name] = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  summary_metrics.append({\n",
        "      'ablation_name': ablation_name,\n",
        "      'Accuracy': accuracy_score(y_test, y_pred),\n",
        "      'F1 (weighted)': f1_score(y_test, y_pred, average='weighted'),\n",
        "      'AUC (weighted)': roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted'),\n",
        "      'Epochs': mlp.n_iter_,\n",
        "      'Training time (s)': end - start,\n",
        "  })\n",
        "  print(f\"Model converged in {mlp.n_iter_} epochs (max_iter was {mlp.max_iter}).\")\n",
        "  print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C8nQOC348Uz",
        "outputId": "5f4f72c6-3b4e-41fd-890b-fb02d9afa3e0"
      },
      "outputs": [],
      "source": [
        "summary_df = pd.DataFrame(summary_metrics)\n",
        "print(summary_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTjZs30C7THa",
        "outputId": "08b65b37-593b-4ea8-b2a9-42a59ae056fd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "for name, loss_curve in all_loss_curves.items():\n",
        "    plt.plot(loss_curve, label=name, alpha=0.8)\n",
        "\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "# plt.title('Training Loss Curves for All Ablations', fontsize=16)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps5NwWDA7oFq",
        "outputId": "3895ae25-b4bd-4494-d74e-570c1e18bd40"
      },
      "outputs": [],
      "source": [
        "# create a 3x4 grid for 12 plots\n",
        "\n",
        "fig, axes = plt.subplots(3, 4, figsize=(20, 20))\n",
        "axes_flat = axes.flatten()\n",
        "\n",
        "if len(all_cms) > len(axes_flat):\n",
        "    print(\"Warning: More ablations than available subplots. Some CMs won't be plotted.\")\n",
        "\n",
        "for i, (name, cm) in enumerate(all_cms.items()):\n",
        "    if i >= len(axes_flat):\n",
        "        break\n",
        "\n",
        "    ax = axes_flat[i]\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "    disp.plot(cmap=plt.cm.GnBu, ax=ax, xticks_rotation='vertical', colorbar=False)\n",
        "    ax.set_title(name, fontsize=12)\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_ylabel('')\n",
        "\n",
        "# fig.colorbar(disp.im_, ax=axes.ravel().tolist(), shrink=0.7)\n",
        "# plt.suptitle('Confusion Matrices for All Ablations', fontsize=20, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2qcKggmIH8T"
      },
      "source": [
        "# 3. Fashion-MNIST image classification  using pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9IQwhgcIVOl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# scale to [0,1], add channel dimension -> (N, 1, 28, 28)\n",
        "X_train = (X_train.astype(\"float32\") / 255.0)[:, None, :, :]\n",
        "X_test  = (X_test.astype(\"float32\")  / 255.0)[:,  None, :, :]\n",
        "\n",
        "y_train = y_train.astype(np.int64)\n",
        "y_test  = y_test.astype(np.int64)\n",
        "\n",
        "# train/val split: last 10k of train as validation\n",
        "X_tr, X_val = X_train[:50000], X_train[50000:]\n",
        "y_tr, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "# wrap in PyTorch TensorDatasets and DataLoaders\n",
        "train_ds = TensorDataset(torch.from_numpy(X_tr),  torch.from_numpy(y_tr))\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE * 2, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE * 2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0REsDBunNmEl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# In colab, you should ``change runtime type'' to GPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dw-JPXEQRTHn"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Detected that PyTorch and torchvision were compiled with different CUDA major versions. PyTorch has CUDA Version=12.6 and torchvision has CUDA Version=13.0. Please reinstall the torchvision that matches your PyTorch install.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlr_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReduceLROnPlateau\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/mds_hw3/lib/python3.10/site-packages/torchvision/__init__.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/mds_hw3/lib/python3.10/site-packages/torchvision/extension.py:92\u001b[0m\n\u001b[1;32m     88\u001b[0m     lib_path \u001b[38;5;241m=\u001b[39m _get_extension_path(lib_name)\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mload_library(lib_path)\n\u001b[0;32m---> 92\u001b[0m \u001b[43m_check_cuda_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/mds_hw3/lib/python3.10/site-packages/torchvision/extension.py:78\u001b[0m, in \u001b[0;36m_check_cuda_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     t_minor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(t_version[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t_major \u001b[38;5;241m!=\u001b[39m tv_major:\n\u001b[0;32m---> 78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected that PyTorch and torchvision were compiled with different CUDA major versions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch has CUDA Version=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_major\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_minor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and torchvision has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA Version=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtv_major\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtv_minor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease reinstall the torchvision that matches your PyTorch install.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _version\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Detected that PyTorch and torchvision were compiled with different CUDA major versions. PyTorch has CUDA Version=12.6 and torchvision has CUDA Version=13.0. Please reinstall the torchvision that matches your PyTorch install."
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torchvision.models as models\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Define class names for plotting\n",
        "class_names = [\n",
        "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuujejCSSXsU"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, scheduler=None, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Generic training loop for a PyTorch model.\n",
        "    \"\"\"\n",
        "    print(f\"--- Training {model_name} ---\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Store history\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': []\n",
        "    }\n",
        "\n",
        "    model.to(device) # Move model to device\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # --- Training Phase ---\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
        "        epoch_train_acc = correct_train / total_train\n",
        "\n",
        "        # --- Validation Phase ---\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
        "        epoch_val_acc = correct_val / total_val\n",
        "\n",
        "        # Log history\n",
        "        history['train_loss'].append(epoch_train_loss)\n",
        "        history['train_acc'].append(epoch_train_acc)\n",
        "        history['val_loss'].append(epoch_val_loss)\n",
        "        history['val_acc'].append(epoch_val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f} - Train Acc: {epoch_train_acc:.4f} | \"\n",
        "              f\"Val Loss: {epoch_val_loss:.4f} - Val Acc: {epoch_val_acc:.4f}\")\n",
        "\n",
        "        # LR Scheduler step\n",
        "        if scheduler and isinstance(scheduler, ReduceLROnPlateau):\n",
        "            scheduler.step(epoch_val_loss)\n",
        "        elif scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "    end_time = time.time()\n",
        "    train_time = end_time - start_time\n",
        "    print(f\"Finished Training. Total time: {train_time:.2f}s\")\n",
        "\n",
        "    return history, train_time\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the test set and returns accuracy and predictions.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    return acc, all_labels, all_preds\n",
        "\n",
        "def plot_metrics(history, model_name):\n",
        "    \"\"\"\n",
        "    Plots training & validation accuracy and loss.\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "    fig.suptitle(f'{model_name} - Training Metrics', fontsize=16)\n",
        "\n",
        "    # accuracy\n",
        "    ax1.plot(history['train_acc'], label='Train Accuracy')\n",
        "    ax1.plot(history['val_acc'], label='Validation Accuracy')\n",
        "    ax1.set_title('Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # loss\n",
        "    ax2.plot(history['train_loss'], label='Train Loss')\n",
        "    ax2.plot(history['val_loss'], label='Validation Loss')\n",
        "    ax2.set_title('Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(all_labels, all_preds, class_names, model_name):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix - {model_name}', fontsize=16)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "# store all results here for final comparison\n",
        "results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSWmK3ihSprR"
      },
      "outputs": [],
      "source": [
        "# Multi-layer perceptron or fully connected network (FCN)\n",
        "\n",
        "class FCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FCN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_stack = nn.Sequential(\n",
        "            nn.Linear(1 * 28 * 28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2), # Add dropout for regularization\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 10) # 10 output classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.fc_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcYyOY8uSzn_"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 20\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAR1olsRTCXO"
      },
      "outputs": [],
      "source": [
        "# SGD optim\n",
        "\n",
        "model_fcn_sgd = FCN()\n",
        "optimizer_sgd = optim.SGD(model_fcn_sgd.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "history_fcn_sgd, time_fcn_sgd = train_model(\n",
        "    model_fcn_sgd, criterion, optimizer_sgd,\n",
        "    train_loader, val_loader, NUM_EPOCHS,\n",
        "    model_name=\"FCN (SGD)\"\n",
        ")\n",
        "\n",
        "acc_fcn_sgd, _, _ = evaluate_model(model_fcn_sgd, test_loader)\n",
        "results['FCN (SGD)'] = {\n",
        "    'history': history_fcn_sgd,\n",
        "    'time': time_fcn_sgd,\n",
        "    'test_acc': acc_fcn_sgd\n",
        "}\n",
        "plot_metrics(history_fcn_sgd, \"FCN (SGD)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_YpQ94XTGGR"
      },
      "outputs": [],
      "source": [
        "# Adam optim\n",
        "\n",
        "model_fcn_adam = FCN()\n",
        "optimizer_adam = optim.Adam(model_fcn_adam.parameters(), lr=0.001)\n",
        "\n",
        "history_fcn_adam, time_fcn_adam = train_model(\n",
        "    model_fcn_adam, criterion, optimizer_adam,\n",
        "    train_loader, val_loader, NUM_EPOCHS,\n",
        "    model_name=\"FCN (Adam)\"\n",
        ")\n",
        "\n",
        "acc_fcn_adam, _, _ = evaluate_model(model_fcn_adam, test_loader)\n",
        "results['FCN (Adam)'] = {\n",
        "    'history': history_fcn_adam,\n",
        "    'time': time_fcn_adam,\n",
        "    'test_acc': acc_fcn_adam\n",
        "}\n",
        "plot_metrics(history_fcn_adam, \"FCN (Adam)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAnJyIVCTPOY"
      },
      "outputs": [],
      "source": [
        "# adam optim & reduceLROnPlateau\n",
        "\n",
        "model_fcn_sched = FCN()\n",
        "optimizer_sched = optim.Adam(model_fcn_sched.parameters(), lr=0.001)\n",
        "scheduler_sched = ReduceLROnPlateau(optimizer_sched, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "history_fcn_sched, time_fcn_sched = train_model(\n",
        "    model_fcn_sched, criterion, optimizer_sched,\n",
        "    train_loader, val_loader, NUM_EPOCHS,\n",
        "    scheduler=scheduler_sched,\n",
        "    model_name=\"FCN (Adam + Scheduler)\"\n",
        ")\n",
        "\n",
        "acc_fcn_sched, labels_fcn, preds_fcn = evaluate_model(model_fcn_sched, test_loader)\n",
        "results['FCN (Adam + Scheduler)'] = {\n",
        "    'history': history_fcn_sched,\n",
        "    'time': time_fcn_sched,\n",
        "    'test_acc': acc_fcn_sched,\n",
        "    'labels': labels_fcn,\n",
        "    'preds': preds_fcn\n",
        "}\n",
        "plot_metrics(history_fcn_sched, \"FCN (Adam + Scheduler)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma-GGNOMTb17"
      },
      "outputs": [],
      "source": [
        "# CNN\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            # Input: (N, 1, 28, 28)\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            # (N, 32, 28, 28)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # (N, 32, 14, 14)\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            # (N, 64, 14, 14)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            # (N, 64, 7, 7)\n",
        "        )\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc_stack = nn.Sequential(\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 10) # 10 output classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_stack(x)\n",
        "        x = self.flatten(x)\n",
        "        logits = self.fc_stack(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "We'll train this model using our best setup from Model 1: Adam + ReduceLROnPlateau.\n",
        "\n",
        "model_cnn = CNN()\n",
        "optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
        "scheduler_cnn = ReduceLROnPlateau(optimizer_cnn, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "history_cnn, time_cnn = train_model(\n",
        "    model_cnn, criterion, optimizer_cnn,\n",
        "    train_loader, val_loader, NUM_EPOCHS,\n",
        "    scheduler=scheduler_cnn,\n",
        "    model_name=\"CNN (Adam + Scheduler)\"\n",
        ")\n",
        "\n",
        "acc_cnn, labels_cnn, preds_cnn = evaluate_model(model_cnn, test_loader)\n",
        "results['CNN'] = {\n",
        "    'history': history_cnn,\n",
        "    'time': time_cnn,\n",
        "    'test_acc': acc_cnn,\n",
        "    'labels': labels_cnn,\n",
        "    'preds': preds_cnn\n",
        "}\n",
        "plot_metrics(history_cnn, \"CNN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbMqzHFdTorB"
      },
      "outputs": [],
      "source": [
        "# transfer learning\n",
        "\n",
        "def create_resnet18_for_fashion_mnist():\n",
        "    \"\"\"\n",
        "    Creates a ResNet18 model modified for 1-channel, 28x28 input\n",
        "    and 10 output classes.\n",
        "    \"\"\"\n",
        "    # Load pretrained ResNet18\n",
        "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # --- 1. Modify conv1 for 1 input channel ---\n",
        "    # Get weights from original 3-channel conv\n",
        "    original_weights = model.conv1.weight.data\n",
        "\n",
        "    # Create new 1-channel conv layer\n",
        "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    # Initialize new weights by averaging old ones across the input channel dim\n",
        "    with torch.no_grad():\n",
        "        model.conv1.weight.data = original_weights.mean(dim=1, keepdim=True)\n",
        "\n",
        "    # --- 2. Modify fc layer for 10 output classes ---\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "    return model\n",
        "\n",
        "model_resnet = create_resnet18_for_fashion_mnist()\n",
        "optimizer_resnet = optim.Adam(model_resnet.parameters(), lr=0.0001) # Use a smaller LR for fine-tuning\n",
        "scheduler_resnet = ReduceLROnPlateau(optimizer_resnet, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "history_resnet, time_resnet = train_model(\n",
        "    model_resnet, criterion, optimizer_resnet,\n",
        "    train_loader, val_loader, NUM_EPOCHS,\n",
        "    scheduler=scheduler_resnet,\n",
        "    model_name=\"ResNet18 (Fine-Tuned)\"\n",
        ")\n",
        "\n",
        "acc_resnet, labels_resnet, preds_resnet = evaluate_model(model_resnet, test_loader)\n",
        "results['ResNet18'] = {\n",
        "    'history': history_resnet,\n",
        "    'time': time_resnet,\n",
        "    'test_acc': acc_resnet,\n",
        "    'labels': labels_resnet,\n",
        "    'preds': preds_resnet\n",
        "}\n",
        "plot_metrics(history_resnet, \"ResNet18\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QG-0q3uSTzzx"
      },
      "outputs": [],
      "source": [
        "print(\"--- Final Model Comparison ---\")\n",
        "print(f\"| Model                   | Test Accuracy | Train Time (s) |\")\n",
        "print(f\"|-------------------------|---------------|----------------|\")\n",
        "for name, res in results.items():\n",
        "    if 'test_acc' in res:\n",
        "        print(f\"| {name:<23} | {res['test_acc'] * 100:>13.2f}% | {res['time']:>14.2f} |\")\n",
        "\n",
        "# plot confusion matrices for the best FCN, the CNN, and ResNet\n",
        "plot_confusion_matrix(results['FCN (Adam + Scheduler)']['labels'],\n",
        "                      results['FCN (Adam + Scheduler)']['preds'],\n",
        "                      class_names, \"FCN (Best)\")\n",
        "\n",
        "plot_confusion_matrix(results['CNN']['labels'],\n",
        "                      results['CNN']['preds'],\n",
        "                      class_names, \"CNN\")\n",
        "\n",
        "plot_confusion_matrix(results['ResNet18']['labels'],\n",
        "                      results['ResNet18']['preds'],\n",
        "                      class_names, \"ResNet18\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mds_hw3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
